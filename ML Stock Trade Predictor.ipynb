{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML Stock Trade Predictor.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"IOjZczKzpScc"},"source":["# Dependencies to Visualize the model\n","import numpy as np\n","import pandas as pd\n","np.random.seed(0)\n","\n","# Filepaths, numpy, and Tensorflow\n","import os\n","import numpy as np\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"46ngXQY4tMTS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf10e453-3224-44b8-9254-78c9fe96ab34"},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n","\n","!pip install pyspark\n","from pyspark.sql import SparkSession\n","spark = SparkSession \\\n","    .builder \\\n","    .getOrCreate()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n","Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n","\u001b[K     |█████████████████████████████   | 184.9MB 1.3MB/s eta 0:00:16"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9OqQCAXHtMqC"},"source":["pip install yfinance"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BUUjnTPOBTgm"},"source":["# Yahoo Finance"]},{"cell_type":"code","metadata":{"id":"9ycbtxQiCzf5"},"source":["import yfinance as yf\n","\n","# tickers = yf.Tickers('msft aapl goog')\n","# # ^ returns a named tuple of Ticker objects\n","\n","# # access each ticker using (example)\n","# tickers.tickers.MSFT.info\n","# tickers.tickers.AAPL.history(period=\"1mo\")\n","# tickers.tickers.GOOG.actions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6VHFn8InN-jt","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"error","timestamp":1605839381348,"user_tz":300,"elapsed":415,"user":{"displayName":"Kamar A-R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEvo5dPqRSZm92VCfeQd_W9SbPMc-LiwopjbO6=s64","userId":"15534887911190721530"}},"outputId":"c3e2940b-46a7-4e90-b05b-b9151e2b2f12"},"source":["# Read in data from S3 Buckets\n","from pyspark import SparkFiles\n","url =\"https://ml-project3.s3.ca-central-1.amazonaws.com/final_finance_data.csv\"\n","spark.sparkContext.addFile(url)\n","stock_data_df = spark.read.csv(SparkFiles.get(\"final_finance_data.csv\"), sep=\",\", header=True)\n","\n","# Show DataFrame\n","stock_data_df.show()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-62670b67d6d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"https://ml-project3.s3.ca-central-1.amazonaws.com/final_finance_data.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstock_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSparkFiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"final_finance_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Show DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/tmp/spark-3b4d68db-1258-44c9-aeb3-16f1caec73ab/userFiles-f84aa1d3-1d9f-4e61-b385-8b9fce270153/final_finance_data.csv;"]}]},{"cell_type":"code","metadata":{"id":"_RpuCXhRgAsD"},"source":["from pyspark.sql.functions import length\n","# Create a length column to be used as a future feature \n","stock_data_df = df.withColumn('length', length(df['text']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tf6-bTpCHFY-","colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"status":"ok","timestamp":1605747699060,"user_tz":300,"elapsed":603,"user":{"displayName":"Kamar A-R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEvo5dPqRSZm92VCfeQd_W9SbPMc-LiwopjbO6=s64","userId":"15534887911190721530"}},"outputId":"e57f8447-4c76-4744-97db-a8b169d0baf3"},"source":["stock_data_df['Price Change'] = stock_data_df['Close'] - stock_data_df['Open']\n","stock_data_df['% Price Change'] = stock_data_df['Price Change'] / stock_data_df['Open']\n","\n","stock_data_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Adj Close</th>\n","      <th>Volume</th>\n","      <th>Price Change</th>\n","      <th>% Price Change</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2020-01-02</th>\n","      <td>158.779999</td>\n","      <td>160.729996</td>\n","      <td>158.330002</td>\n","      <td>160.619995</td>\n","      <td>159.352386</td>\n","      <td>22622100</td>\n","      <td>1.839996</td>\n","      <td>0.011588</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-03</th>\n","      <td>158.320007</td>\n","      <td>159.949997</td>\n","      <td>158.059998</td>\n","      <td>158.619995</td>\n","      <td>157.368179</td>\n","      <td>21116200</td>\n","      <td>0.299988</td>\n","      <td>0.001895</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-06</th>\n","      <td>157.080002</td>\n","      <td>159.100006</td>\n","      <td>156.509995</td>\n","      <td>159.029999</td>\n","      <td>157.774948</td>\n","      <td>20813700</td>\n","      <td>1.949997</td>\n","      <td>0.012414</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-07</th>\n","      <td>159.320007</td>\n","      <td>159.669998</td>\n","      <td>157.320007</td>\n","      <td>157.580002</td>\n","      <td>156.336395</td>\n","      <td>21634100</td>\n","      <td>-1.740005</td>\n","      <td>-0.010921</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-08</th>\n","      <td>158.929993</td>\n","      <td>160.800003</td>\n","      <td>157.949997</td>\n","      <td>160.089996</td>\n","      <td>158.826569</td>\n","      <td>27746500</td>\n","      <td>1.160004</td>\n","      <td>0.007299</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-12</th>\n","      <td>217.210007</td>\n","      <td>219.110001</td>\n","      <td>214.460007</td>\n","      <td>215.440002</td>\n","      <td>215.440002</td>\n","      <td>21593900</td>\n","      <td>-1.770004</td>\n","      <td>-0.008149</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-13</th>\n","      <td>216.360001</td>\n","      <td>217.419998</td>\n","      <td>214.160004</td>\n","      <td>216.509995</td>\n","      <td>216.509995</td>\n","      <td>18621100</td>\n","      <td>0.149994</td>\n","      <td>0.000693</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-16</th>\n","      <td>214.869995</td>\n","      <td>217.740005</td>\n","      <td>214.520004</td>\n","      <td>217.229996</td>\n","      <td>217.229996</td>\n","      <td>24953300</td>\n","      <td>2.360001</td>\n","      <td>0.010983</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-17</th>\n","      <td>216.100006</td>\n","      <td>217.679993</td>\n","      <td>214.080002</td>\n","      <td>214.460007</td>\n","      <td>214.460007</td>\n","      <td>24125100</td>\n","      <td>-1.639999</td>\n","      <td>-0.007589</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-18</th>\n","      <td>213.649994</td>\n","      <td>215.169998</td>\n","      <td>210.929993</td>\n","      <td>211.080002</td>\n","      <td>211.080002</td>\n","      <td>26804161</td>\n","      <td>-2.569992</td>\n","      <td>-0.012029</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>224 rows × 8 columns</p>\n","</div>"],"text/plain":["                  Open        High  ...  Price Change  % Price Change\n","Date                                ...                              \n","2020-01-02  158.779999  160.729996  ...      1.839996        0.011588\n","2020-01-03  158.320007  159.949997  ...      0.299988        0.001895\n","2020-01-06  157.080002  159.100006  ...      1.949997        0.012414\n","2020-01-07  159.320007  159.669998  ...     -1.740005       -0.010921\n","2020-01-08  158.929993  160.800003  ...      1.160004        0.007299\n","...                ...         ...  ...           ...             ...\n","2020-11-12  217.210007  219.110001  ...     -1.770004       -0.008149\n","2020-11-13  216.360001  217.419998  ...      0.149994        0.000693\n","2020-11-16  214.869995  217.740005  ...      2.360001        0.010983\n","2020-11-17  216.100006  217.679993  ...     -1.639999       -0.007589\n","2020-11-18  213.649994  215.169998  ...     -2.569992       -0.012029\n","\n","[224 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"HY5qOXI59tMb"},"source":["def hold(column, tolerance=0.01):\n","  if abs(column) > tolerance and column > 0:\n","    return 'buy'\n","  elif abs(column) > tolerance and column < 0:\n","    return 'sell'\n","  else: \n","    return 'hold'\n","\n","stock_data_df['action'] = stock_data_df['% Price Change'].apply(hold)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nd4mptFb9tPh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605747703487,"user_tz":300,"elapsed":446,"user":{"displayName":"Kamar A-R","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgEvo5dPqRSZm92VCfeQd_W9SbPMc-LiwopjbO6=s64","userId":"15534887911190721530"}},"outputId":"efe35fcf-0cf5-451d-9db6-bd48f9bda96c"},"source":["stock_data_df['action']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Date\n","2020-01-02     buy\n","2020-01-03    hold\n","2020-01-06     buy\n","2020-01-07    sell\n","2020-01-08    hold\n","              ... \n","2020-11-12    hold\n","2020-11-13    hold\n","2020-11-16     buy\n","2020-11-17    hold\n","2020-11-18    sell\n","Name: action, Length: 224, dtype: object"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"NYnjYUXJ9tSp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ekaEQrCvBBSo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6HgCs8sdKpkx"},"source":["# NaiveBayes Machine Learning"]},{"cell_type":"code","metadata":{"id":"8UYZnY3SKyTX"},"source":["# Read in data from file\n","from pyspark import SparkFiles\n","\n","## Import upload data into AWS server##\n","# file name: ml_finance_data\n","\n","url =\"Resources/'aws_url\"\n","spark.sparkContext.addFile(url)\n","df = spark.read.csv(SparkFiles.get(\"stock_data.csv\"), sep=\",\", header=True)\n","\n","# Show DataFrame\n","df.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vwypqZliKydJ"},"source":["from pyspark.sql.functions import length\n","# Create a length column to be used as a future feature \n","data_df = df.withColumn('length', length(df['text']))\n","data_df.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zaXWXKDpKygb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"haFkoExuL4Vn"},"source":["Feature Transformations"]},{"cell_type":"code","metadata":{"id":"M8zfDaoLMET_"},"source":["from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n","# Create all the features to the data set\n","pos_neg_to_num = StringIndexer(inputCol='action',outputCol='label')\n","tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n","stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n","hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n","idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fThZPVoAMEWe"},"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.linalg import Vector\n","\n","# Create feature vectors\n","clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZngCjQupMEY7"},"source":["# Create a and run a data processing Pipeline\n","from pyspark.ml import Pipeline\n","data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXwP3okJMEe2"},"source":["# Fit and transform the pipeline\n","cleaner = data_prep_pipeline.fit(data_df)\n","cleaned = cleaner.transform(data_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-wWnapZMEhM"},"source":["# Show label and resulting features\n","cleaned.select(['label', 'features']).show(truncate = False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I4YXfDGEMiYS"},"source":["NaiveBayes"]},{"cell_type":"code","metadata":{"id":"WCXm0JFQMnlE"},"source":["from pyspark.ml.classification import NaiveBayes\n","# Break data down into a training set and a testing set\n","training, testing = cleaned.randomSplit([0.7, 0.3])\n","\n","# Create a Naive Bayes model and fit training data\n","nb = NaiveBayes()\n","predictor = nb.fit(training)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wjWX83IsMnrL"},"source":["# Tranform the model with the testing data\n","test_results = predictor.transform(testing)\n","test_results.show(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"od8GO6BhMnth"},"source":["# Use the Class Evaluator for a cleaner description\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","acc_eval = MulticlassClassificationEvaluator()\n","acc = acc_eval.evaluate(test_results)\n","print(\"Accuracy of model at predicting reviews was: %f\" % acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAWbwaKyMnw5"},"source":["# Save the model\n","predictor.save('Trade_Predictor_Model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CojbRPLiMn2N"},"source":[""],"execution_count":null,"outputs":[]}]}